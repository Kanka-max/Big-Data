{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe99336-1267-4e2c-814a-7b28ebc5f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ CSV extract:\n",
      "+----+--------------------+--------------------+----+--------------------+------+\n",
      "|Rank|                Song|              Artist|Year|              Lyrics|Source|\n",
      "+----+--------------------+--------------------+----+--------------------+------+\n",
      "|   1|         wooly bully|sam the sham and ...|1965|sam the sham misc...|     3|\n",
      "|   2|i cant help mysel...|           four tops|1965| sugar pie honey ...|     1|\n",
      "|   3|i cant get no sat...|  the rolling stones|1965|                    |     1|\n",
      "|   4| you were on my mind|             we five|1965| when i woke up t...|     1|\n",
      "|   5|youve lost that l...|the righteous bro...|1965| you never close ...|     1|\n",
      "|   6|            downtown|        petula clark|1965| when youre alone...|     1|\n",
      "|   7|                help|         the beatles|1965|help i need someb...|     3|\n",
      "|   8|cant you hear my ...|     hermans hermits|1965|carterlewis every...|     5|\n",
      "|   9|crying in the chapel|       elvis presley|1965| you saw me cryin...|     1|\n",
      "|  10|             my girl|     the temptations|1965|ive got sunshine ...|     3|\n",
      "|  11|      help me rhonda|      the beach boys|1965|well since she pu...|     3|\n",
      "|  12|    king of the road|        roger miller|1965| trailer for sale...|     1|\n",
      "|  13|the birds and the...|         jewel akens|1965|let me tell ya bo...|     3|\n",
      "|  14|hold me thrill me...|          mel carter|1965| hold me hold me ...|     1|\n",
      "|  15|             shotgun|junior walker  th...|1965|i said ̢shotgun s...|     3|\n",
      "|  16|      i got you babe|         sonny  cher|1965|they say were you...|     3|\n",
      "|  17|   this diamond ring|gary lewis  the p...|1965|who wants to buy ...|     3|\n",
      "|  18|        the in crowd|   ramsey lewis trio|1965|        instrumental|     3|\n",
      "|  19|mrs brown youve g...|     hermans hermits|1965| mrs brown youve ...|     1|\n",
      "|  20|stop in the name ...|        the supremes|1965| stop in the name...|     1|\n",
      "+----+--------------------+--------------------+----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a dataset of lyrics from billboard songs, \n",
    "# and find the most common words used over time.\n",
    "\n",
    "import sys\n",
    "\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "spark = SparkSession\\\n",
    "  .builder \\\n",
    "  .appName(\"PythonWordCount\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "# Read CSV from OVHcloud Object Storage https://github.com/walkerkq/musiclyrics\n",
    "data = spark.read.format('csv').options(header='true', inferSchema='true') \\\n",
    "  .load('billboard_lyrics_1964-2015.csv') \\\n",
    "\n",
    "print('############ CSV extract:')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9770dc0a-76ea-4b15-aff0-654606c84d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| you|64606|\n",
      "|   i|56466|\n",
      "| the|53451|\n",
      "|  to|35752|\n",
      "| and|32555|\n",
      "|  me|31170|\n",
      "|   a|29282|\n",
      "|  it|25688|\n",
      "|  my|22821|\n",
      "|  in|18553|\n",
      "|that|16151|\n",
      "|  on|15814|\n",
      "|your|15459|\n",
      "|love|15283|\n",
      "|  im|14278|\n",
      "|  be|13004|\n",
      "|  of|12825|\n",
      "|    |12266|\n",
      "| all|11895|\n",
      "|dont|11587|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count and group word frequencies on the column Lyrics, when splitted by space comma\n",
    "# The explode() function will take the data inside the Lyrics column, \n",
    "# and separate all the data found based on the separator “whitespace character”.\n",
    "\n",
    "data.withColumn('word', f.explode(f.split(f.col('Lyrics'), ' '))) \\\n",
    "  .groupBy('word') \\\n",
    "  .count() \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58694b64-58c1-4799-a98a-09543ab99584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Tokenized data extract:\n",
      "+----+--------------------+\n",
      "|Rank|         words_token|\n",
      "+----+--------------------+\n",
      "|   1|[sam, the, sham, ...|\n",
      "|   2|[, sugar, pie, ho...|\n",
      "|   3|                  []|\n",
      "|   4|[, when, i, woke,...|\n",
      "|   5|[, you, never, cl...|\n",
      "|   6|[, when, youre, a...|\n",
      "|   7|[help, i, need, s...|\n",
      "|   8|[carterlewis, eve...|\n",
      "|   9|[, you, saw, me, ...|\n",
      "|  10|[ive, got, sunshi...|\n",
      "|  11|[well, since, she...|\n",
      "|  12|[, trailer, for, ...|\n",
      "|  13|[let, me, tell, y...|\n",
      "|  14|[, hold, me, hold...|\n",
      "|  15|[i, said, ̢shotgu...|\n",
      "|  16|[they, say, were,...|\n",
      "|  17|[who, wants, to, ...|\n",
      "|  18|      [instrumental]|\n",
      "|  19|[, mrs, brown, yo...|\n",
      "|  20|[, stop, in, the,...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To remove stop words (like \"I\", \"The\", ...), we need to provide arrays of words, not strings. Here we use APache Spark Tokenizer to do so.\n",
    "# We create a new column to push our arrays of words\n",
    "tokenizer = Tokenizer(inputCol=\"Lyrics\", outputCol=\"words_token\")\n",
    "tokenized = tokenizer.transform(data).select('Rank','words_token')\n",
    "\n",
    "print('############ Tokenized data extract:')\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e94085-fe19-4670-89f3-7c87e70090df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Data Cleaning extract:\n",
      "+----+--------------------+\n",
      "|Rank|         words_clean|\n",
      "+----+--------------------+\n",
      "|   1|[sam, sham, misce...|\n",
      "|   2|[, sugar, pie, ho...|\n",
      "|   3|                  []|\n",
      "|   4|[, woke, morning,...|\n",
      "|   5|[, never, close, ...|\n",
      "|   6|[, youre, alone, ...|\n",
      "|   7|[help, need, some...|\n",
      "|   8|[carterlewis, eve...|\n",
      "|   9|[, saw, crying, c...|\n",
      "|  10|[ive, got, sunshi...|\n",
      "|  11|[well, since, put...|\n",
      "|  12|[, trailer, sale,...|\n",
      "|  13|[let, tell, ya, b...|\n",
      "|  14|[, hold, hold, ne...|\n",
      "|  15|[said, ̢shotgun, ...|\n",
      "|  16|[say, young, dont...|\n",
      "|  17|[wants, buy, diam...|\n",
      "|  18|      [instrumental]|\n",
      "|  19|[, mrs, brown, yo...|\n",
      "|  20|[, stop, name, lo...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Once in arrays, we can use the Apache Spark function StopWordsRemover\n",
    "# A new column \"words_clean\" is here as an output\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "data_clean = remover.transform(tokenized).select('Rank', 'words_clean')\n",
    "\n",
    "print('############ Data Cleaning extract:')\n",
    "data_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ffd0698-29ad-4ecf-8eab-2a3579f7f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ TOP20 Most used words in Billboard songs are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "| love|15283|\n",
      "|   im|14278|\n",
      "| dont|11587|\n",
      "| know|11166|\n",
      "| like|10949|\n",
      "|   oh| 9736|\n",
      "| baby| 9098|\n",
      "|  got| 8289|\n",
      "|  get| 8265|\n",
      "|     | 7982|\n",
      "|youre| 6592|\n",
      "| yeah| 6259|\n",
      "| want| 6214|\n",
      "|   go| 6105|\n",
      "| make| 5520|\n",
      "|  one| 5412|\n",
      "| cant| 5338|\n",
      "|  see| 5264|\n",
      "| time| 5176|\n",
      "|  let| 4927|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final step : like in the beginning, we can group again words and sort them by the most used\n",
    "result = data_clean.withColumn('word', f.explode(f.col('words_clean'))) \\\n",
    "  .groupBy('word') \\\n",
    "  .count().sort('count', ascending=False) \\\n",
    "\n",
    "print('############ TOP20 Most used words in Billboard songs are:')\n",
    "result.show()\n",
    "\n",
    "# Stop Spark Process\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a49739-4427-472f-ad6f-c7bb3f7995db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  if we analyze the lyrics of most famous songs during the last 50 years, the word “love” comes in first position with 15283 occurences. \n",
    "# Followed by “i’m”, “don’t”, “know”, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad605ed0-02f2-4270-a34a-1fb4f19f216d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b9eba1-2320-4ca2-9de4-ce1c526e2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ CSV extract:\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          ALink|               SName|               SLink|               Lyric|               Idiom|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|/10000-maniacs/|      More Than This|/10000-maniacs/mo...|I could feel at t...|             ENGLISH|\n",
      "|/10000-maniacs/|   Because The Night|/10000-maniacs/be...|Take me now, baby...|             ENGLISH|\n",
      "|/10000-maniacs/|      These Are Days|/10000-maniacs/th...|These are. These ...|             ENGLISH|\n",
      "|/10000-maniacs/|     A Campfire Song|/10000-maniacs/a-...|\"A lie to say, \"\"...| \"\"O my. river wh...|\n",
      "|/10000-maniacs/|Everyday Is Like ...|/10000-maniacs/ev...|Trudging slowly o...|             ENGLISH|\n",
      "|/10000-maniacs/|          Don't Talk|/10000-maniacs/do...|Don't talk, I wil...|             ENGLISH|\n",
      "|/10000-maniacs/|   Across The Fields|/10000-maniacs/ac...|Well they left th...|             ENGLISH|\n",
      "|/10000-maniacs/|Planned Obsolescence|/10000-maniacs/pl...|[ music: Dennis D...|             ENGLISH|\n",
      "|/10000-maniacs/|           Rainy Day|/10000-maniacs/ra...|On bended kneeI'v...|             ENGLISH|\n",
      "|/10000-maniacs/|Anthem For Doomed...|/10000-maniacs/an...|For whom do the b...|             ENGLISH|\n",
      "|/10000-maniacs/|All That Never Ha...|/10000-maniacs/al...|She walks alone o...|             ENGLISH|\n",
      "|/10000-maniacs/|    Back O' The Moon|/10000-maniacs/ba...|Jenny. Jenny you ...|             ENGLISH|\n",
      "|/10000-maniacs/|A Room For Everyt...|/10000-maniacs/a-...|You were looking ...|             ENGLISH|\n",
      "|/10000-maniacs/|    Like The Weather|/10000-maniacs/li...|\"The color of the...|. \"\"What a cold a...|\n",
      "|/10000-maniacs/|         Eat For Two|/10000-maniacs/ea...|\"Oh,. Baby blanke...|      . Walk for two|\n",
      "|/10000-maniacs/|        Maddox Table|/10000-maniacs/ma...|\"the legs of Madd...|             ENGLISH|\n",
      "|/10000-maniacs/|Can't Ignore The ...|/10000-maniacs/ca...|Steep is the wate...|             ENGLISH|\n",
      "|/10000-maniacs/|   To Sir, With Love|/10000-maniacs/to...|[original version...|             ENGLISH|\n",
      "|/10000-maniacs/|  Stockton Gala Days|/10000-maniacs/st...|That summer field...|             ENGLISH|\n",
      "|/10000-maniacs/|  Poison In The Well|/10000-maniacs/po...|[ music: Dennis D...|             ENGLISH|\n",
      "+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scrapped lyrics from 6 genres, \n",
    "# and find the most common words used over time.\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "spark = SparkSession\\\n",
    "  .builder \\\n",
    "  .appName(\"PythonWordCount\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "# Read CSV \n",
    "data = spark.read.format('csv').options(header='true', inferSchema='true') \\\n",
    "  .load('lyrics-data.csv') \\\n",
    "\n",
    "print('############ CSV extract:')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b8b74c-db9b-47f7-896c-93bc47ca5664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|word|  count|\n",
      "+----+-------+\n",
      "|   I|1016667|\n",
      "| the| 981725|\n",
      "|   a| 801613|\n",
      "| you| 732151|\n",
      "|  to| 590347|\n",
      "|  me| 491956|\n",
      "| que| 423262|\n",
      "|  my| 375483|\n",
      "| and| 361048|\n",
      "|  de| 324536|\n",
      "|  in| 313670|\n",
      "|   o| 300001|\n",
      "|  it| 296355|\n",
      "| I'm| 281620|\n",
      "|your| 263533|\n",
      "|  of| 252005|\n",
      "| And| 249278|\n",
      "|  eu| 232985|\n",
      "|that| 226913|\n",
      "|  on| 225446|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.withColumn('word', f.explode(f.split(f.col('Lyric'), ' '))) \\\n",
    "  .groupBy('word') \\\n",
    "  .count() \\\n",
    "  .sort('count', ascending=False) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6766091a-8f2d-490c-ac1c-c83e8261bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Tokenized data extract:\n",
      "+--------------------+\n",
      "|         words_token|\n",
      "+--------------------+\n",
      "|[i, could, feel, ...|\n",
      "|[take, me, now,, ...|\n",
      "|[these, are., the...|\n",
      "|[\"a, lie, to, say...|\n",
      "|[trudging, slowly...|\n",
      "|[don't, talk,, i,...|\n",
      "|[well, they, left...|\n",
      "|[[, music:, denni...|\n",
      "|[on, bended, knee...|\n",
      "|[for, whom, do, t...|\n",
      "|[she, walks, alon...|\n",
      "|[jenny., jenny, y...|\n",
      "|[you, were, looki...|\n",
      "|[\"the, color, of,...|\n",
      "|[\"oh,., baby, bla...|\n",
      "|[\"the, legs, of, ...|\n",
      "|[steep, is, the, ...|\n",
      "|[[original, versi...|\n",
      "|[that, summer, fi...|\n",
      "|[[, music:, denni...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Lyric\", outputCol=\"words_token\")\n",
    "tokenized = tokenizer.transform(data).select('words_token')\n",
    "\n",
    "print('############ Tokenized data extract:')\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e2b2dff-bbc1-484b-8509-4f6179b02f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Data Cleaning extract:\n",
      "+--------------------+\n",
      "|         words_clean|\n",
      "+--------------------+\n",
      "|[feel, time., way...|\n",
      "|[take, now,, baby...|\n",
      "|[are., days, reme...|\n",
      "|[\"a, lie, say,, \"...|\n",
      "|[trudging, slowly...|\n",
      "|[talk,, listen., ...|\n",
      "|[well, left, morn...|\n",
      "|[[, music:, denni...|\n",
      "|[bended, kneei've...|\n",
      "|[bells, toll., se...|\n",
      "|[walks, alone, br...|\n",
      "|[jenny., jenny, k...|\n",
      "|[looking, away, m...|\n",
      "|[\"the, color, sky...|\n",
      "|[\"oh,., baby, bla...|\n",
      "|[\"the, legs, madd...|\n",
      "|[steep, water, to...|\n",
      "|[[original, versi...|\n",
      "|[summer, fields, ...|\n",
      "|[[, music:, denni...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "data_clean = remover.transform(tokenized).select('words_clean')\n",
    "\n",
    "print('############ Data Cleaning extract:')\n",
    "data_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8245b1-3bbc-4bdc-b6cf-a68b972f25d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef52b6-2f84-4d98-a67e-5f3cc21fce2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
